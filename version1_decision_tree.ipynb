{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-20T15:37:16.700288Z",
     "iopub.status.busy": "2024-11-20T15:37:16.699774Z",
     "iopub.status.idle": "2024-11-20T15:37:16.705480Z",
     "shell.execute_reply": "2024-11-20T15:37:16.704195Z",
     "shell.execute_reply.started": "2024-11-20T15:37:16.700246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:37:16.708394Z",
     "iopub.status.busy": "2024-11-20T15:37:16.708000Z",
     "iopub.status.idle": "2024-11-20T15:37:43.532744Z",
     "shell.execute_reply": "2024-11-20T15:37:43.531648Z",
     "shell.execute_reply.started": "2024-11-20T15:37:16.708360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load in the json file\n",
    "data = []\n",
    "with open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    " \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:37:43.534401Z",
     "iopub.status.busy": "2024-11-20T15:37:43.534029Z",
     "iopub.status.idle": "2024-11-20T15:37:45.684666Z",
     "shell.execute_reply": "2024-11-20T15:37:45.683599Z",
     "shell.execute_reply.started": "2024-11-20T15:37:43.534367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load in csv files provided\n",
    "emotion_list = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\n",
    "data_idenfication = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:37:45.686292Z",
     "iopub.status.busy": "2024-11-20T15:37:45.685933Z",
     "iopub.status.idle": "2024-11-20T15:37:55.571548Z",
     "shell.execute_reply": "2024-11-20T15:37:55.570643Z",
     "shell.execute_reply.started": "2024-11-20T15:37:45.686252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# merge the data of the json file with csv data\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})\n",
    "df = df.merge(data_idenfication, on='tweet_id', how='left')\n",
    "\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:37:55.573094Z",
     "iopub.status.busy": "2024-11-20T15:37:55.572769Z",
     "iopub.status.idle": "2024-11-20T15:37:58.441396Z",
     "shell.execute_reply": "2024-11-20T15:37:58.440276Z",
     "shell.execute_reply.started": "2024-11-20T15:37:55.573064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# merge emotion list onto df\n",
    "train_data = train_data.merge(emotion_list, on='tweet_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:37:58.443476Z",
     "iopub.status.busy": "2024-11-20T15:37:58.443111Z",
     "iopub.status.idle": "2024-11-20T15:37:59.367738Z",
     "shell.execute_reply": "2024-11-20T15:37:59.366854Z",
     "shell.execute_reply.started": "2024-11-20T15:37:58.443443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# drop the duplicates of training data\n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_data = train_data.sample(frac=1)\n",
    "test_data = test_data.sample(frac=1)\n",
    "\n",
    "print(\"Shape of Training df: \", train_data.shape)\n",
    "print(\"Shape of Testing df: \", test_d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## save to pickle file\n",
    "train_data.to_pickle(\"train_df.pkl\")\n",
    "test_data.to_pickle(\"test_df.pkl\")\n",
    "\n",
    "## load a pickle file\n",
    "train_data = pd.read_pickle(\"train_df.pkl\")\n",
    "test_data = pd.read_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:37:59.369300Z",
     "iopub.status.busy": "2024-11-20T15:37:59.368946Z",
     "iopub.status.idle": "2024-11-20T15:38:00.290006Z",
     "shell.execute_reply": "2024-11-20T15:38:00.288926Z",
     "shell.execute_reply.started": "2024-11-20T15:37:59.369268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:38:00.293302Z",
     "iopub.status.busy": "2024-11-20T15:38:00.292889Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize, \n",
    "                         token_pattern=None)\n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(train_data['text'])\n",
    "\n",
    "train_data_BOW_features_500 = BOW_500.transform(train_data['text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = BOW_500.transform(train_data['text'])\n",
    "y_train = train_data['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(train_data['text'])\n",
    "y_test = train_data['emotion']\n",
    "\n",
    "## take a look at data dimension is a good habit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# build the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'tweet_id': test_data['tweet_id'],\n",
    "    'identification': y_pred_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# turn the submission file to csv\n",
    "submission.to_csv('/kaggle/working/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9912598,
     "sourceId": 87232,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
