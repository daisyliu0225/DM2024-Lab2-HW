{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":87232,"databundleVersionId":9912598,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Load Data","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport numpy as np\nimport nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:37:16.699774Z","iopub.execute_input":"2024-11-20T15:37:16.700288Z","iopub.status.idle":"2024-11-20T15:37:16.705480Z","shell.execute_reply.started":"2024-11-20T15:37:16.700246Z","shell.execute_reply":"2024-11-20T15:37:16.704195Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data = []\nwith open('/kaggle/input/dm-2024-isa-5810-lab-2-homework/tweets_DM.json', 'r') as f:\n    for line in f:\n        data.append(json.loads(line))\n \nf.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:37:16.708000Z","iopub.execute_input":"2024-11-20T15:37:16.708394Z","iopub.status.idle":"2024-11-20T15:37:43.532744Z","shell.execute_reply.started":"2024-11-20T15:37:16.708360Z","shell.execute_reply":"2024-11-20T15:37:43.531648Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"emotion_list = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/emotion.csv')\ndata_idenfication = pd.read_csv('/kaggle/input/dm-2024-isa-5810-lab-2-homework/data_identification.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:37:43.534029Z","iopub.execute_input":"2024-11-20T15:37:43.534401Z","iopub.status.idle":"2024-11-20T15:37:45.684666Z","shell.execute_reply.started":"2024-11-20T15:37:43.534367Z","shell.execute_reply":"2024-11-20T15:37:45.683599Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df = pd.DataFrame(data)\n_source = df['_source'].apply(lambda x: x['tweet'])\ndf = pd.DataFrame({\n    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n    'hashtags': _source.apply(lambda x: x['hashtags']),\n    'text': _source.apply(lambda x: x['text']),\n})\ndf = df.merge(data_idenfication, on='tweet_id', how='left')\n\ntrain_data = df[df['identification'] == 'train']\ntest_data = df[df['identification'] == 'test']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:37:45.685933Z","iopub.execute_input":"2024-11-20T15:37:45.686292Z","iopub.status.idle":"2024-11-20T15:37:55.571548Z","shell.execute_reply.started":"2024-11-20T15:37:45.686252Z","shell.execute_reply":"2024-11-20T15:37:55.570643Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_data = train_data.merge(emotion_list, on='tweet_id', how='left')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:37:55.572769Z","iopub.execute_input":"2024-11-20T15:37:55.573094Z","iopub.status.idle":"2024-11-20T15:37:58.441396Z","shell.execute_reply.started":"2024-11-20T15:37:55.573064Z","shell.execute_reply":"2024-11-20T15:37:58.440276Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_data.drop_duplicates(subset=['text'], keep=False, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:37:58.443111Z","iopub.execute_input":"2024-11-20T15:37:58.443476Z","iopub.status.idle":"2024-11-20T15:37:59.367738Z","shell.execute_reply.started":"2024-11-20T15:37:58.443443Z","shell.execute_reply":"2024-11-20T15:37:59.366854Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# shuffle dataset\ntrain_data = train_data.sample(frac=1)\ntest_data = test_data.sample(frac=1)\n\nprint(\"Shape of Training df: \", train_data.shape)\nprint(\"Shape of Testing df: \", test_d.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save to pickle","metadata":{}},{"cell_type":"code","source":"## save to pickle file\ntrain_data.to_pickle(\"train_df.pkl\")\ntest_data.to_pickle(\"test_df.pkl\")\n\n## load a pickle file\ntrain_data = pd.read_pickle(\"train_df.pkl\")\ntest_data = pd.read_pickle(\"test_df.pkl\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Decision Tree model","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\nnltk.download('punkt_tab')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:37:59.368946Z","iopub.execute_input":"2024-11-20T15:37:59.369300Z","iopub.status.idle":"2024-11-20T15:38:00.290006Z","shell.execute_reply.started":"2024-11-20T15:37:59.369268Z","shell.execute_reply":"2024-11-20T15:38:00.288926Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# build analyzers (bag-of-words)\nBOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize, \n                         token_pattern=None)\n\n# apply analyzer to training data\nBOW_500.fit(train_data['text'])\n\ntrain_data_BOW_features_500 = BOW_500.transform(train_data['text'])\n\n## check dimension\ntrain_data_BOW_features_500.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T15:38:00.292889Z","iopub.execute_input":"2024-11-20T15:38:00.293302Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# for a classificaiton problem, you need to provide both training & testing data\nX_train = BOW_500.transform(train_data['text'])\ny_train = train_data['emotion']\n\nX_test = BOW_500.transform(train_data['text'])\ny_test = train_data['emotion']\n\n## take a look at data dimension is a good habit  :)\nprint('X_train.shape: ', X_train.shape)\nprint('y_train.shape: ', y_train.shape)\nprint('X_test.shape: ', X_test.shape)\nprint('y_test.shape: ', y_test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## build DecisionTree model\nDT_model = DecisionTreeClassifier(random_state=1)\n\n## training!\nDT_model = DT_model.fit(X_train, y_train)\n\n## predict!\ny_train_pred = DT_model.predict(X_train)\ny_test_pred = DT_model.predict(X_test)\n\n## so we get the pred result\ny_test_pred[:10]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## accuracy\nfrom sklearn.metrics import accuracy_score\n\nacc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\nacc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n\nprint('training accuracy: {}'.format(round(acc_train, 2)))\nprint('testing accuracy: {}'.format(round(acc_test, 2)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## precision, recall, f1-score,\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(y_true=y_test, y_pred=y_test_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'tweet_id': test_data['tweet_id'],\n    'identification': y_pred_labels\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('/kaggle/working/submission.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}